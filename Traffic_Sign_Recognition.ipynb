{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b6ac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Classes Detected: 43\n",
      "Importing Classes.....\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  \n",
      "Data Shapes\n",
      "Train(22271, 32, 32, 3) (22271,)\n",
      "Validation(5568, 32, 32, 3) (5568,)\n",
      "Test(6960, 32, 32, 3) (6960,)\n",
      "data shape  (43, 2) <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tejasree\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,560</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,060</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,230</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,130</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">240,500</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">21,543</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m60\u001b[0m)          │           \u001b[38;5;34m1,560\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m60\u001b[0m)          │          \u001b[38;5;34m90,060\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m60\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m30\u001b[0m)          │          \u001b[38;5;34m16,230\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m30\u001b[0m)            │           \u001b[38;5;34m8,130\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m30\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m30\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m480\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)                 │         \u001b[38;5;34m240,500\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m)                  │          \u001b[38;5;34m21,543\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">378,023</span> (1.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m378,023\u001b[0m (1.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">378,023</span> (1.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m378,023\u001b[0m (1.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tejasree\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m695/695\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 122ms/step - accuracy: 0.1612 - loss: 3.0871 - val_accuracy: 0.7620 - val_loss: 0.8306\n",
      "Epoch 2/10\n",
      "\u001b[1m  1/695\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 91ms/step - accuracy: 0.4375 - loss: 1.8595"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tejasree\\AppData\\Local\\Programs\\Python\\Python39\\lib\\contextlib.py:135: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(type, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m695/695\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.4375 - loss: 0.9311 - val_accuracy: 0.7683 - val_loss: 0.8286\n",
      "Epoch 3/10\n",
      "\u001b[1m695/695\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 131ms/step - accuracy: 0.5729 - loss: 1.3892 - val_accuracy: 0.9258 - val_loss: 0.3205\n",
      "Epoch 4/10\n",
      "\u001b[1m695/695\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.7500 - loss: 0.4524 - val_accuracy: 0.9273 - val_loss: 0.3223\n",
      "Epoch 5/10\n",
      "\u001b[1m695/695\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 202ms/step - accuracy: 0.7228 - loss: 0.8871 - val_accuracy: 0.9389 - val_loss: 0.2361\n",
      "Epoch 6/10\n",
      "\u001b[1m695/695\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.8750 - loss: 0.2759 - val_accuracy: 0.9406 - val_loss: 0.2394\n",
      "Epoch 7/10\n",
      "\u001b[1m695/695\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 189ms/step - accuracy: 0.7947 - loss: 0.6590 - val_accuracy: 0.9689 - val_loss: 0.1204\n",
      "Epoch 8/10\n",
      "\u001b[1m695/695\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.8438 - loss: 0.2206 - val_accuracy: 0.9707 - val_loss: 0.1170\n",
      "Epoch 9/10\n",
      "\u001b[1m 81/695\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:09\u001b[0m 211ms/step - accuracy: 0.8360 - loss: 0.5383"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    " \n",
    "path = \"Dataset\" \n",
    "labelFile = 'labels.csv' \n",
    "batch_size_val=32 \n",
    "epochs_val=10\n",
    "imageDimesions = (32,32,3)\n",
    "testRatio = 0.2    \n",
    "validationRatio = 0.2 \n",
    "\n",
    "count = 0\n",
    "images = []\n",
    "classNo = []\n",
    "myList = os.listdir(path)\n",
    "print(\"Total Classes Detected:\",len(myList))\n",
    "noOfClasses=len(myList)\n",
    "print(\"Importing Classes.....\")\n",
    "for x in range (0,len(myList)):\n",
    "    myPicList = os.listdir(path+\"/\"+str(count))\n",
    "    for y in myPicList:\n",
    "        curImg = cv2.imread(path+\"/\"+str(count)+\"/\"+y)\n",
    "        images.append(curImg)\n",
    "        classNo.append(count)\n",
    "    print(count, end =\" \")\n",
    "    count +=1\n",
    "print(\" \")\n",
    "images = np.array(images)\n",
    "classNo = np.array(classNo)\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(images, classNo, test_size=testRatio)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validationRatio)\n",
    " \n",
    "\n",
    "print(\"Data Shapes\")\n",
    "print(\"Train\",end = \"\");print(X_train.shape,y_train.shape)\n",
    "print(\"Validation\",end = \"\");print(X_validation.shape,y_validation.shape)\n",
    "print(\"Test\",end = \"\");print(X_test.shape,y_test.shape)\n",
    "\n",
    "\n",
    "data=pd.read_csv(labelFile)\n",
    "print(\"data shape \",data.shape,type(data))\n",
    " \n",
    "num_of_samples = []\n",
    "cols = 5\n",
    "num_classes = noOfClasses\n",
    "\n",
    "def grayscale(img):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    return img\n",
    "def equalize(img):\n",
    "    img =cv2.equalizeHist(img)\n",
    "    return img\n",
    "def preprocessing(img):\n",
    "    img = grayscale(img)     \n",
    "    img = equalize(img)      \n",
    "    img = img/255            \n",
    "    return img\n",
    " \n",
    "X_train=np.array(list(map(preprocessing,X_train)))  \n",
    "X_validation=np.array(list(map(preprocessing,X_validation)))\n",
    "X_test=np.array(list(map(preprocessing,X_test)))\n",
    "\n",
    "\n",
    "X_train=X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\n",
    "X_validation=X_validation.reshape(X_validation.shape[0],X_validation.shape[1],X_validation.shape[2],1)\n",
    "X_test=X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)\n",
    " \n",
    " \n",
    "dataGen= ImageDataGenerator(width_shift_range=0.1,   \n",
    "                            height_shift_range=0.1,\n",
    "                            zoom_range=0.2,  \n",
    "                            shear_range=0.1,  \n",
    "                            rotation_range=10)  \n",
    "dataGen.fit(X_train)\n",
    "batches= dataGen.flow(X_train,y_train,batch_size=20)\n",
    "X_batch,y_batch = next(batches)\n",
    " \n",
    "\n",
    "y_train = to_categorical(y_train,noOfClasses)\n",
    "y_validation = to_categorical(y_validation,noOfClasses)\n",
    "y_test = to_categorical(y_test,noOfClasses)\n",
    "\n",
    "\n",
    "def myModel():\n",
    "    model= Sequential()\n",
    "    model.add((Conv2D(60,(5,5),input_shape=(imageDimesions[0],imageDimesions[1],1),activation='relu')))  # ADDING MORE CONVOLUTION LAYERS = LESS FEATURES BUT CAN CAUSE ACCURACY TO INCREASE\n",
    "    model.add((Conv2D(60, (5,5), activation='relu')))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    " \n",
    "    model.add((Conv2D(30, (3,3),activation='relu')))\n",
    "    model.add((Conv2D(30, (3,3), activation='relu')))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    " \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(noOfClasses,activation='softmax')) \n",
    "    #model.compile(Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    model.compile(Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    " \n",
    "model = myModel()\n",
    "print(model.summary())\n",
    "history = model.fit(dataGen.flow(X_train, y_train, batch_size=batch_size_val), \n",
    "                    steps_per_epoch=len(X_train) // 32, \n",
    "                    epochs=epochs_val, \n",
    "                    validation_data=(X_validation, y_validation),\n",
    "                    shuffle=1)\n",
    " \n",
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['training','validation'])\n",
    "plt.title('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.figure(2)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['training','validation'])\n",
    "plt.title('Acurracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "score =model.evaluate(X_test,y_test,verbose=0)\n",
    "print('Test Score:',score[0])\n",
    "print('Test Accuracy:',score[1])\n",
    " \n",
    "model.save(\"model2.h5\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8905207-0760-4e60-ba09-a26d54d0488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Functions for preprocessing\n",
    "def grayscale(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img\n",
    "\n",
    "def equalize(img):\n",
    "    img = cv2.equalizeHist(img)\n",
    "    return img\n",
    "\n",
    "def preprocess_new_image(img):\n",
    "    img = grayscale(img)\n",
    "    img = equalize(img)\n",
    "    img = img / 255\n",
    "    return img\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(\"model.h5\")\n",
    "\n",
    "# Load and preprocess new images\n",
    "def load_and_preprocess_images(image_paths):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, (32, 32))  # Resize the image to match model input shape\n",
    "        img = preprocess_new_image(img)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Load class names from labels.csv\n",
    "labels_df = pd.read_csv('labels.csv', header=None)\n",
    "class_names = dict(zip(labels_df[0], labels_df[1]))\n",
    "\n",
    "# Paths to new images\n",
    "new_image_paths = [\"uploads/img1.png\", \"uploads/img2.png\", \"uploads/img3.png\", \"uploads/img4.png\"]\n",
    "\n",
    "# Load and preprocess the new images\n",
    "new_images = load_and_preprocess_images(new_image_paths)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(new_images)\n",
    "\n",
    "# Get the class with the highest probability for each prediction\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Display the images with their predicted class names\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(len(new_image_paths)):\n",
    "    plt.subplot(1, len(new_image_paths), i + 1)\n",
    "    plt.imshow(new_images[i], cmap='gray')\n",
    "    predicted_class_name = class_names[str(predicted_classes[i])]\n",
    "    plt.title(\"Predicted: \" + predicted_class_name)\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
